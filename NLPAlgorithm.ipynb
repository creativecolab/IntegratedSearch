{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "33df90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import plotly.express as px \n",
    "import pandas as pd \n",
    "from newspaper import Article\n",
    "from textblob import TextBlob, Word\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34ebbd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get DOM of website, returned as BautifulSoup object\n",
    "#USE THIS FUNCTION'S OUTPUT FOR OTHER FUNCTIONS \n",
    "def scrape_website(url):\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "    return soup #as parsed siteDocument\n",
    "\n",
    "#Get p tags of BeautifulSoup object, used to parse webpages visited \n",
    "def get_site_article(beautifulSoupObj):\n",
    "    texts=set()\n",
    "    for link in beautifulSoupObj.find_all('p'):\n",
    "        texts.append(link.get_text())\n",
    "    return texts\n",
    "\n",
    "#Get each result header from Google search page\n",
    "def get_query_headers(beautifulSoupObj):\n",
    "    texts=set()\n",
    "    for link in beautifulSoupObj.find_all('div', class_='BNeawe vvjwJb AP7Wnd'):\n",
    "        texts.add(link.get_text())\n",
    "    return texts\n",
    "\n",
    "#Get each result description from Google search page\n",
    "def get_query_results_descriptions(beautifulSoupObj):\n",
    "    texts=set()\n",
    "    for link in beautifulSoupObj.find_all('div', class_='BNeawe s3v9rd AP7Wnd'):\n",
    "        texts.add(link.get_text())\n",
    "    return texts\n",
    "\n",
    "#Get common questions section from Google search page\n",
    "def get_query_common_questions(beautifulSoupObj):\n",
    "    texts=set()\n",
    "    for link in beautifulSoupObj.find_all('div', class_='Lt3Tzc'):\n",
    "        texts.add(link.get_text())\n",
    "    return texts\n",
    "\n",
    "#Get query related searches from Google search page\n",
    "def get_query_related_searches(beautifulSoupObj):\n",
    "    texts=set()\n",
    "    for link in beautifulSoupObj.find_all('div', class_='BNeawe s3v9rd AP7Wnd lRVwie'):\n",
    "        texts.add(link.get_text())\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a45e2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape website\n",
    "#Don't scrape google query site too often\n",
    "websitedom=scrape_website('https://www.google.com/search?q=scrape+google+search&num=100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a1bb21df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11 SERP APIs to Scrape Search Engine Results in 2021',\n",
       " '9 Best SERP API to Scrape Real-time Search Engine Results Data',\n",
       " 'AI-Powered Web Scraping Tool & Web Data Extractor | ScrapeStorm',\n",
       " 'Can I scrape the search results from the Google AJAX Search API if ...',\n",
       " 'Data Scraper - Easy Web Scraping - Google Chrome - Download ...',\n",
       " 'Facebook, Google, YouTube order Clearview to stop scraping ...',\n",
       " 'Five Tools to Scrape Search Results | Boolean Strings',\n",
       " 'Free Google Search scraper and SERP API · Apify',\n",
       " 'Google Is Again Allowed to Scrape Content From Yelp, Other ...',\n",
       " 'Google Meta Scraper - ScrapeBox',\n",
       " 'Google Scraper 101 | Easy Data Technology | Scraping Robot',\n",
       " 'Google Search Result Scraper, Google Data Extractor',\n",
       " 'Google Search Results Scraper Online Tool | BOTSTER.io',\n",
       " 'Google Search Results Scraping | Scrape Google Search Data',\n",
       " 'Google Search SERP Scraper API Documentation (jaypat87 ...',\n",
       " 'Google web scraping service. Scrape Google search results. Google ...',\n",
       " 'GoogleScraper Tutorial - How to scrape 1000 keywords with Google ...',\n",
       " 'How I scraped data from Google Scholar - Nature',\n",
       " 'How To Scrape Google Image Search? - Fearlessflyer.com',\n",
       " 'How To Scrape Google Search Results R - Herunterladen',\n",
       " 'How To Scrape Google With Python | Hacker Noon',\n",
       " \"How We Analyzed Google's Search Results – The Markup\",\n",
       " 'How to Crawl Google Search Results - Octoparse Insights',\n",
       " 'How to Scrape Google Results for Free Using Python – Predictive ...',\n",
       " 'How to Scrape Google SERPs to Optimize for Search Intent',\n",
       " 'How to Scrape Google Search Features Using XPath | Screaming Frog',\n",
       " 'How to Scrape Google Search Result Page using Python ...',\n",
       " 'How to Scrape Google Search Results For Free - GainTap',\n",
       " 'How to Scrape Google Search Results Quickly, Easily and for Free ...',\n",
       " 'How to Scrape Google Search Results inside a Google Sheet ...',\n",
       " 'How to Scrape Google Search Results using Python Scrapy ...',\n",
       " 'How to Scrape Google Search Results with Python - ScraperBox',\n",
       " 'How to Scrape Google Shopping Prices with Web Data Extraction ...',\n",
       " 'How to Scrape Google Using XPath - JC Chouinard',\n",
       " 'How to Scrape Google Without Coding | ScrapeHero Cloud',\n",
       " 'How to Scrape Info from Google SERPs with Screaming Frog in 2021',\n",
       " 'How to Scrape SERP Snippets with Python Coding | 3Q Digital',\n",
       " 'How to Scrape Search Results from a List of Keywords | ParseHub',\n",
       " 'How to Scrape Websites Using Google Sheets Formulas (Examples ...',\n",
       " 'How to scrape 1,000 Google search result links in 5 minutes.',\n",
       " 'How to scrape Google Autocomplete with Excel - Giuseppe Pastore',\n",
       " 'How to scrape Google Places in Python | Outscraper',\n",
       " 'How to scrape Google Search | Proxy Crawl - Anonymous crawler ...',\n",
       " 'How to scrape Google search result pages (SERPs)? | netnut.io',\n",
       " 'How to scrape Google search results using Python',\n",
       " 'How to scrape a website with a searchbar - Data Science Stack ...',\n",
       " 'How to scrape data from Google Shopping ? - WebHarvy',\n",
       " 'How to scrape google search data with data scraping and save it ...',\n",
       " 'How to scrape google search results data with out getting blocked ...',\n",
       " 'How to scrape google search results into excel | MrExcel Message ...',\n",
       " 'How to scrape search results from search engines like Google, Bing ...',\n",
       " 'How to scrape search-engine results?: AskProgramming - Reddit',\n",
       " 'How to: Scrape Google Search Results with Python [Tutorial ...',\n",
       " 'ImportFromWeb | Easy Web Scraping - Google Workspace ...',\n",
       " 'Impossible to scrape google search results.. Right? - Google Groups',\n",
       " 'Is it legal to scrape data from a Google search result? - Quora',\n",
       " 'Is it ok to scrape data from Google results? - Stack Overflow',\n",
       " 'Quick Tip: Consuming Google Search results to use for web scraping',\n",
       " 'SERP scraping, kw tracking, kw analysis, LinkedIn scraping by and ...',\n",
       " 'Scrape 100 Google search results in 30 seconds (No Coding)',\n",
       " 'Scrape Google Maps Search Results Data - Pinterest',\n",
       " 'Scrape Google SERPs with Screaming Frog | SEO North',\n",
       " 'Scrape Google Search Results for any Country - Scrapingdog',\n",
       " 'Scrape Google Search Results to CSV using VBA - Analyst Cave',\n",
       " 'Scrape Google Search Results using Python ... - GeeksforGeeks',\n",
       " 'Scrape Google Search Results using Python ... - JournalDev',\n",
       " 'Scrape Google Search Results using Python BeautifulSoup - Morioh',\n",
       " 'Scrape Google Search Results | Dibz',\n",
       " 'Scrape Google Search results using Google APIs - AutoIt General ...',\n",
       " 'Scrape Google by our Google Search Result API - All SERP',\n",
       " 'Scrape Google search results of specific date range - Python - Bytes',\n",
       " 'Scrape Google-Search results page in PHP for total results and ...',\n",
       " 'Scrape and export the results of a Google Maps search along with ...',\n",
       " 'Scrape data via Google Searching | Octoparse',\n",
       " 'Scrape google search results in bulk by Fabikraus | Fiverr',\n",
       " 'Scrape google search results python | Semalt Q&A',\n",
       " 'Scrape google search snippet results - C# PDF SDK',\n",
       " 'Scrape the Google Autosuggest with Python – PEMAVOR',\n",
       " 'Scrape the SERPs with Web Scraper (Chrome extension) - Daniel ...',\n",
       " 'Scrape top 100 search results with Google Docs | SEO[Thing]',\n",
       " 'Scraped content | Search Central | Google Developers',\n",
       " 'Scraping 1 million keywords on the Google ... - incolumitas.com',\n",
       " \"Scraping Google's Search Engine With Python — A Step-by-Step ...\",\n",
       " 'Scraping Millions of Google SERPs The Easy Way (Python Scrapy ...',\n",
       " 'Scraping Search Results From Google Search | PS Chua',\n",
       " 'Scraping websites using the Scraper extension for Chrome | School ...',\n",
       " 'Search engine scraping - Wikipedia',\n",
       " 'Search engine scraping services | API for SEO-software companies ...',\n",
       " 'SerpApi: Google Search API',\n",
       " 'The Best Google Scrapers of 2021 | How to Scrape Google SERPs ...',\n",
       " 'Tips to Scrape Google Search Results Effectively | DataOx',\n",
       " 'Unlimited Scraping Google Search Results - Thousands of Results ...',\n",
       " 'Web Scraping Google search Results | MyDataProvider',\n",
       " 'Web Scraping Using Selenium Python | Selenium for Web Scraping',\n",
       " 'Web scraping: Google search results with Selenium and ... - Medium',\n",
       " 'Which Search Engine is Easiest to Scrape? | RotatingProxies Blog',\n",
       " 'Zenserp - Google Search API | Search Result Scraping with our ...',\n",
       " '[GUIDE] How to scrape Google search results without any scraper ...',\n",
       " 'emacs for scraping Google search results // Bodacious Blog',\n",
       " 'scrape-google · PyPI'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setToString(set):\n",
    "    return '; '.join(set)\n",
    "\n",
    "headers=get_query_headers(websitedom)\n",
    "headersString=setToString(headers)\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c5911ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrape google maps search\n",
      "data\n",
      "pinterest\n",
      "scrape google\n",
      "prices\n",
      "web data extraction\n",
      "best google scrapers\n",
      "scrape google serps\n",
      "scrape search\n",
      "list\n",
      "keywords\n",
      "parsehub\n",
      "web scraping\n",
      "selenium python\n",
      "selenium\n",
      "web scraping\n",
      "quick tip\n",
      "consuming google search\n",
      "search\n",
      "wikipedia\n",
      "scrape google serps\n",
      "optimize\n",
      "search intent\n",
      "google\n",
      "search result pages\n",
      "serps\n",
      " netnutio\n",
      "scrape websites\n",
      "google sheets formulas\n",
      "examples\n",
      "web\n",
      "google\n",
      "search results\n",
      "selenium\n",
      "medium\n",
      "web scraping google\n",
      "mydataprovider\n",
      "scrape google serps\n",
      "screaming frog\n",
      "seo\n",
      "scrapegoogle \n",
      "pypi\n",
      "serpapi\n",
      "google search api\n",
      "scrape\n",
      "google maps\n",
      "guide\n",
      "google\n",
      "search results\n",
      "scraper \n",
      "scrape google\n",
      "free\n",
      "python\n",
      "predictive\n",
      "scrape google search results\n",
      "excel \n",
      "mrexcel message\n",
      "search engine\n",
      "easiest\n",
      "scrape\n",
      "rotatingproxies blog\n",
      "google\n",
      "search results\n",
      "python\n",
      "aipowered web scraping tool\n",
      "web data extractor\n",
      "scrapestorm\n",
      "scrape google search\n",
      "google sheet\n",
      "scrape google search\n",
      "page\n",
      "python\n",
      "google places\n",
      "python\n",
      "outscraper\n",
      "google\n",
      "allowed\n",
      "scrape content\n",
      "yelp\n",
      "scrape google search\n",
      "google apis\n",
      "autoit\n",
      "general \n",
      "scrape google search\n",
      "scrapingdog\n",
      "scrape google search\n",
      "dibz\n",
      "google search\n",
      "proxy crawl\n",
      "anonymous\n",
      "crawler \n",
      "google scholar\n",
      "nature\n",
      "scraped\n",
      "content \n",
      "search\n",
      "central \n",
      "google developers\n",
      "googlescraper tutorial\n",
      "google\n",
      "scrape\n",
      "google\n",
      "search results\n",
      "coding\n",
      "scrape googlesearch\n",
      "results page\n",
      "php\n",
      "total results\n",
      "scrape google search\n",
      "python\n",
      "geeksforgeeks\n",
      "google\n",
      "search results \n",
      "bodacious blog\n",
      "free google search\n",
      "serp api\n",
      "apify\n",
      "impossible\n",
      "scrape google search results \n",
      "right\n",
      "google groups\n",
      "scrape google search data\n",
      "scraping google\n",
      "search engine\n",
      "python\n",
      "stepbystep\n",
      "scrape google search\n",
      "quickly\n",
      "easily\n",
      "free\n",
      "scrape google search\n",
      "free\n",
      "gaintap\n",
      "data\n",
      "stack\n",
      "scrape google search results data\n",
      "scrape info\n",
      "google serps\n",
      "screaming frog\n",
      "scrape google\n",
      "search results\n",
      "specific date range\n",
      "python\n",
      "bytes\n",
      "scrape google search features\n",
      "xpath\n",
      "screaming frog\n",
      "analyzed google\n",
      "search\n",
      "markup\n",
      "scrape data\n",
      "google\n",
      "webharvy\n",
      "scrape serp snippets\n",
      "python coding\n",
      " q\n",
      "digital\n",
      "serp api\n",
      "scrape realtime search engine\n",
      "data\n",
      "google search serp scraper api documentation\n",
      "jaypat \n",
      "google meta scraper\n",
      "scrapebox\n",
      "scrape data\n",
      "google\n",
      "search result\n",
      "quora\n",
      "data scraper\n",
      "easy web scraping\n",
      "google chrome\n",
      "download\n",
      "serp apis\n",
      "scrape search engine\n",
      "scrape\n",
      "google searching\n",
      "octoparse\n",
      "google\n",
      "search result links\n",
      "scraping\n",
      "google\n",
      "google\n",
      "scrape google\n",
      "search results\n",
      "google\n",
      "scrape google\n",
      "google search\n",
      "api\n",
      "serp\n",
      "scrape\n",
      "google search results\n",
      "fabikraus\n",
      "fiverr\n",
      "zenserp\n",
      "google search api\n",
      "search\n",
      "scraping\n",
      "google search\n",
      "scraper online tool\n",
      "botsterio\n",
      "scrape google search\n",
      "python\n",
      "journaldev\n",
      "google scraper\n",
      "easy data\n",
      "technology \n",
      "scraping robot\n",
      "scrape google search\n",
      "csv\n",
      "vba\n",
      "analyst cave\n",
      "scrape\n",
      "google search snippet results\n",
      "c \n",
      "pdf sdk\n",
      "scrape searchengine results\n",
      "askprogramming\n",
      "reddit\n",
      "google search\n",
      "scraper\n",
      "google data extractor\n",
      "scrape google search\n",
      "python\n",
      "scraperbox\n",
      "scraping millions\n",
      "google serps\n",
      "easy\n",
      "python scrapy\n",
      "tools\n",
      "scrape search\n",
      "boolean strings\n",
      "scrape google search\n",
      "herunterladen\n",
      "scraping\n",
      "scraper\n",
      "chrome\n",
      " school \n",
      "scrape google\n",
      "xpath\n",
      "jc chouinard\n",
      "scrape google\n",
      "python\n",
      "hacker noon\n",
      "serp\n",
      "kw analysis\n",
      "linkedin\n",
      "tips\n",
      "scrape google search\n",
      "effectively\n",
      "dataox\n",
      "crawl google search\n",
      "octoparse insights\n",
      "facebook\n",
      "google\n",
      "youtube\n",
      "clearview\n",
      "scrape\n",
      "search results\n",
      "google docs\n",
      "seo\n",
      "thing\n",
      "search results\n",
      "google ajax search api\n",
      "google autocomplete\n",
      "excel\n",
      "giuseppe pastore\n",
      "search\n",
      "services \n",
      "api\n",
      "seosoftware\n",
      "companies \n",
      "scrape google image search\n",
      "fearlessflyercom\n",
      "scraping search\n",
      "google search\n",
      "ps chua\n",
      "google search\n",
      "scraping\n",
      "scrape google search data\n",
      "scrape data\n",
      "google\n",
      "stack overflow\n",
      "scrape\n",
      "google autosuggest\n",
      "python\n",
      "pemavor\n",
      "scrape\n",
      "google search results python \n",
      "semalt q\n",
      "unlimited scraping google search\n",
      "scrape google search\n",
      "python scrapy\n",
      "scrape google\n",
      "coding\n",
      "scrapehero cloud\n",
      "importfromweb\n",
      "easy web scraping\n",
      "google workspace\n",
      "scrape search results\n",
      "search engines\n",
      "google\n",
      "bing\n",
      "scrape google search\n",
      "python\n",
      "tutorial\n",
      "scrape\n",
      "serps\n",
      "web scraper\n",
      "chrome\n",
      "daniel\n",
      "scrape google search\n",
      "python beautifulsoup\n",
      "morioh\n"
     ]
    }
   ],
   "source": [
    "#Do noun phrase extraction, clean up phrases \n",
    "blob = TextBlob(headersString)\n",
    "blob.noun_phrases\n",
    "phrases=blob.noun_phrases\n",
    "for phrase in phrases:\n",
    "    phrase=Word(re.sub(\"[^a-zA-Z ]+\", \"\",phrase))\n",
    "    print(phrase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
